WEBVTT

1
00:00:00.700 --> 00:00:02.830
主成分分析 (Principal components analysis) 和奇异值分解 (Singular value decomposition)

2
00:00:02.830 --> 00:00:05.450
在探索性数据分析和形式化建模阶段

3
00:00:05.450 --> 00:00:07.790
在探索性数据分析和形式化建模阶段

4
00:00:07.790 --> 00:00:10.180
都是非常重要的方法

5
00:00:10.180 --> 00:00:14.850
这些方法在两个阶段中都有很方便的应用

6
00:00:14.850 --> 00:00:16.830
我将会讲一讲在探索性数据分析中怎样使用它们

7
00:00:16.830 --> 00:00:19.110
我将会讲一讲在探索性数据分析中怎样使用它们

8
00:00:19.110 --> 00:00:21.010
我想稍微讲一讲

9
00:00:21.010 --> 00:00:23.740
方法背后的逻辑以及它们的基础是什么

10
00:00:24.770 --> 00:00:25.890
假设这儿我们有些矩阵数据

11
00:00:25.890 --> 00:00:28.130
假设这儿我们有些矩阵数据

12
00:00:28.130 --> 00:00:30.400
我用这里的代码生成了一些随机的正态分布数据

13
00:00:30.400 --> 00:00:32.390
我用这里的代码生成了一些随机的正态分布数据

14
00:00:32.390 --> 00:00:34.230
你可以看到我用 image() 画出来的这个矩阵

15
00:00:34.230 --> 00:00:37.080
并没有特别让人感兴趣的东西

16
00:00:37.080 --> 00:00:39.710
它看起来有很多噪声

17
00:00:39.710 --> 00:00:43.560
和我们预想的一样 也没有什么特别的模式

18
00:00:43.560 --> 00:00:47.140
现在我可以对这个数据集进行层次聚类分析

19
00:00:47.140 --> 00:00:48.820
用层次聚类算法

20
00:00:48.820 --> 00:00:51.070
分析这个数据框或者说数组的行和列

21
00:00:51.070 --> 00:00:52.960
分析这个数据框或者说数组的行和列

22
00:00:52.960 --> 00:00:56.050
我可以用 R 中的 heatmap() 很方便地做到这件事

23
00:00:56.050 --> 00:00:59.140
当运行 heatmap() 之后 你可以看到聚类分析也做完了

24
00:00:59.140 --> 00:01:03.150
在列和行上我都得到了树状图

25
00:01:03.150 --> 00:01:05.350
但是同样 没有出现有意思的模式

26
00:01:05.350 --> 00:01:08.120
因为数据本身就没有包含什么有意思的模式

27
00:01:10.100 --> 00:01:11.990
所以没关系

28
00:01:11.990 --> 00:01:14.060
但是现在 如果我们往数据集里添加一个模式会怎样

29
00:01:14.060 --> 00:01:17.020
那么让我们试着添加一点东西

30
00:01:17.020 --> 00:01:19.470
我用 for 循环写了这样一段程序

31
00:01:19.470 --> 00:01:23.980
我遍历了所有行 在任意行上

32
00:01:23.980 --> 00:01:28.090
如果抛硬币抛得1 我就增加一个模式

33
00:01:28.090 --> 00:01:32.810
其中五列均值为0 另外五列均值为3

34
00:01:32.810 --> 00:01:35.840
其中五列均值为0 另外五列均值为3

35
00:01:35.840 --> 00:01:39.630
我相当于给所有列的数值加了一个偏移

36
00:01:39.630 --> 00:01:42.030
所以现在我再画这些数据

37
00:01:42.030 --> 00:01:44.530
你会看到右边的五列偏黄一点

38
00:01:44.530 --> 00:01:47.420
意味着它们的数值比较大

39
00:01:47.420 --> 00:01:49.220
左边五列比较红

40
00:01:49.220 --> 00:01:51.270
表示它们的数值比较小

41
00:01:51.270 --> 00:01:56.300
这是因为有些行的右边均值是3

42
00:01:57.310 --> 00:02:00.270
有些行的右边均值只有0

43
00:02:00.270 --> 00:02:02.730
所以你可以明显看到有类似阶跃的模式

44
00:02:04.790 --> 00:02:08.130
现在如果我对这些数据进行层次聚类分析

45
00:02:08.130 --> 00:02:10.970
你可以看到

46
00:02:12.080 --> 00:02:14.460
列很容易地被分成了两簇

47
00:02:14.460 --> 00:02:16.060
你可以看到矩阵上方的树状图

48
00:02:16.060 --> 00:02:19.170
分析的是列

49
00:02:19.170 --> 00:02:21.510
它明显分成了两簇

50
00:02:21.510 --> 00:02:23.770
五个分支在左 五个分支在右

51
00:02:23.770 --> 00:02:25.170
在行的方向上不是那么明显

52
00:02:25.170 --> 00:02:28.160
因为行没有什么真正的模式

53
00:02:28.160 --> 00:02:29.890
所以各行重新组织形成新的随机模式

54
00:02:29.890 --> 00:02:35.559
这是 heatmap() 产生的图像

55
00:02:39.100 --> 00:02:42.390
现在我们可以通过计算行和列的边际均值 (marginal mean)

56
00:02:42.390 --> 00:02:43.780
进一步观察行和列的模式

57
00:02:43.780 --> 00:02:47.320
进一步观察行和列的模式

58
00:02:47.320 --> 00:02:50.660
比如我可以画出这个矩阵其中10列的各列的平均值

59
00:02:50.660 --> 00:02:55.280
或者其中40行的各行的平均值

60
00:02:55.280 --> 00:02:56.960
这就是我利用这段代码做出的结果

61
00:02:56.960 --> 00:02:59.760
左边的图是我画的原始矩阵数据

62
00:03:01.430 --> 00:03:04.130
它根据各行层次聚类分析的结果

63
00:03:04.130 --> 00:03:08.960
重新排了序

64
00:03:10.050 --> 00:03:16.870
我在中间的这张图上画的是各行的平均值

65
00:03:16.870 --> 00:03:19.705
y 轴标了行号0到40

66
00:03:19.705 --> 00:03:24.590
基本和左边的图平行

67
00:03:24.590 --> 00:03:27.280
x 轴是该行的平均值

68
00:03:27.280 --> 00:03:29.210
比如你看 第十行的均值大概在-0.25左右

69
00:03:29.210 --> 00:03:33.580
比如你看 第十行的均值大概在-0.25左右

70
00:03:33.580 --> 00:03:36.433
第30行均值大概是1.5

71
00:03:37.490 --> 00:03:43.670
你可看到行的均值有一个明显的偏移

72
00:03:43.670 --> 00:03:46.450
类似地 如果你观察各列 

73
00:03:46.450 --> 00:03:51.490
你会发现十个列的均值也有明显的偏移

74
00:03:51.490 --> 00:03:54.340
前面十列均值大概在0左右 (教授口误 应为前五列)

75
00:03:54.340 --> 00:03:56.510
后面十列均值大概是2 (教授口误 应为后五列)

76
00:03:56.510 --> 00:04:00.890
因为有一个偏移

77
00:04:00.890 --> 00:04:03.140
通过观察中间和右边的图

78
00:04:03.140 --> 00:04:07.130
你可以清楚地看到行和列中的模式

79
00:04:10.770 --> 00:04:14.860
这里讲一些相关的问题

80
00:04:14.860 --> 00:04:17.980
层次聚类分析对于找出这类模式很有用

81
00:04:17.980 --> 00:04:21.290
但是我们或许可以利用数据的矩阵结构

82
00:04:21.290 --> 00:04:24.810
来应用更正规一点的方法

83
00:04:24.810 --> 00:04:26.310
有两种问题需要研究

84
00:04:26.310 --> 00:04:27.710
有两个问题需要研究

85
00:04:27.710 --> 00:04:31.940
第一个是假如你有很多变量

86
00:04:31.940 --> 00:04:35.830
我们想要新建一个非相关的

87
00:04:35.830 --> 00:04:38.260
并且能够尽可能多地展示变化的变量集合

88
00:04:38.260 --> 00:04:40.510
那我们的数据集中有很多不同的变量

89
00:04:40.510 --> 00:04:42.630
假设说有成千上万个变量

90
00:04:42.630 --> 00:04:44.190
假设说有成千上万个变量

91
00:04:44.190 --> 00:04:46.920
问题是他们并不都是独立的测量值

92
00:04:46.920 --> 00:04:51.215
问题是他们并不都是独立的测量值

93
00:04:51.215 --> 00:04:51.270
对吧？

94
00:04:51.270 --> 00:04:52.770
它们当中很多都有一定的相互关系

95
00:04:52.770 --> 00:04:54.000
是互相相关的

96
00:04:54.000 --> 00:04:55.420
比如说 你有两组测量数据

97
00:04:55.420 --> 00:04:57.000
身高和体重

98
00:04:57.000 --> 00:04:58.720
它们是会有明显的相关关系的

99
00:04:58.720 --> 00:05:00.900
所以他们不是完全独立的因子

100
00:05:00.900 --> 00:05:02.030
所以他们不是完全独立的因子

101
00:05:02.030 --> 00:05:05.950
我们想做的是建一个变量集合

102
00:05:05.950 --> 00:05:07.840
它要比原始的变量集合小

103
00:05:07.840 --> 00:05:10.680
并且其中的变量互不相关

104
00:05:10.680 --> 00:05:16.310
它们可以表示数据集中不同类型的变动

105
00:05:16.310 --> 00:05:20.540
类似地 我们想要用这个精简的变量集

106
00:05:20.540 --> 00:05:23.520
来尽可能多地展示数据集的变异性

107
00:05:25.630 --> 00:05:28.990
另一个涉及到的问题是如果你把所有的变量

108
00:05:28.990 --> 00:05:32.550
像我们前面图中看到过的矩阵一样都放到一个矩阵里

109
00:05:32.550 --> 00:05:35.430
你想要找到一个变量尽量少

110
00:05:35.430 --> 00:05:39.360
但仍然可以展示原始数据的最佳矩阵

111
00:05:39.360 --> 00:05:41.800
用术语来讲就是

112
00:05:41.800 --> 00:05:44.010
你要找到一个能够很好地表示原始数据的低秩矩阵

113
00:05:44.010 --> 00:05:46.860
你要找到一个能够很好地表示原始数据的低秩矩阵

114
00:05:46.860 --> 00:05:50.650
第一个目标是统计的问题

115
00:05:50.650 --> 00:05:52.280
通常可以用主成分分析的方法解决

116
00:05:52.280 --> 00:05:56.070
通常可以用主成分分析的方法解决

117
00:05:56.070 --> 00:05:59.210
第二个目标是数据压缩的问题

118
00:05:59.210 --> 00:06:01.310
你要找到一个小一点的变量集来表示原始数据

119
00:06:01.310 --> 00:06:04.600
你要找到一个小一点的变量集来表示原始数据

120
00:06:04.600 --> 00:06:07.670
解决这个问题的方法之一是使用奇异值分解

121
00:06:10.020 --> 00:06:14.610
奇异值分解可以用矩阵形式表示

122
00:06:14.610 --> 00:06:20.130
假设你有一个矩阵 X

123
00:06:20.130 --> 00:06:24.720
我们可以假设矩阵中每一列都是一个变量或者一个测量值

124
00:06:24.720 --> 00:06:26.620
矩阵中的每一行代表一次观测

125
00:06:26.620 --> 00:06:29.730
所以在一个给定的矩阵中你可能会有很多很多次观测

126
00:06:29.730 --> 00:06:31.570
例如 矩阵的不同行可能代表不同的人

127
00:06:31.570 --> 00:06:35.040
而矩阵的每一列表示这些人的一个测量值

128
00:06:35.040 --> 00:06:36.130
而矩阵的每一列表示这些人的一个测量值

129
00:06:36.130 --> 00:06:37.920
比如第一列可能是身高

130
00:06:37.920 --> 00:06:39.690
第二列可能是体重

131
00:06:41.460 --> 00:06:43.750
如果你有一个像这样形式的矩阵 X

132
00:06:43.750 --> 00:06:47.490
如果你有一个像这样形式的矩阵 X

133
00:06:47.490 --> 00:06:51.120
那么奇异值分解或者说 SVD 是一个矩阵分解的方法

134
00:06:51.120 --> 00:06:55.730
它能够将原始矩阵分解成三个独立的矩阵

135
00:06:55.730 --> 00:06:58.900
一个是 U 一个是 D 还有一个是 V

136
00:06:59.960 --> 00:07:03.130
U 的列是正交 (orthogonal) 的

137
00:07:03.130 --> 00:07:05.430
且相互独立的

138
00:07:05.430 --> 00:07:07.580
它们被称为左奇异向量 (left singular vector)

139
00:07:07.580 --> 00:07:10.960
V 的列也是正交的 叫做右奇异向量 (right singular vector)

140
00:07:10.960 --> 00:07:15.080
D 是包含奇异值的对角矩阵 (diagonal matrix)

141
00:07:15.080 --> 00:07:17.480
这就是奇异值分解的基本思想

142
00:07:17.480 --> 00:07:21.020
我们以后会详细讲解这些组成成分

143
00:07:21.020 --> 00:07:25.200
主成分分析 通常叫做 PCA

144
00:07:25.200 --> 00:07:31.040
它利用到了奇异值分解作为相关的方法

145
00:07:31.040 --> 00:07:32.770
基本思想是

146
00:07:32.770 --> 00:07:36.490
如果你有一个原始数据矩阵 

147
00:07:36.490 --> 00:07:40.480
将每一列数都减去这一列的平均值

148
00:07:40.480 --> 00:07:44.080
再除以这一列的标准差

149
00:07:44.080 --> 00:07:47.990
然后对这个重新标准化后的矩阵进行奇异值分解

150
00:07:47.990 --> 00:07:50.590
那么主成分就等于矩阵的右奇异值 

151
00:07:51.930 --> 00:07:54.340
也就是矩阵 V
【教育无边界字幕组】靖哥哥 | hazard1990 | HikaruSama